x-application-base: &application-base
  restart: always
  tty: true
  networks:
    - ai_talks_network

x-environmental-base: &environmental-base
  <<: *application-base
  environment:
    MODEL: "gemma3:1b"

services:
  ai_host:
    <<: *environmental-base
    build:
      context: .
      dockerfile: ./Dockerfile.ollama
      args:
        - MODEL=${MODEL}
    container_name: ai_host
    ports:
      - "10000:11434"

  ai_talks_database:
    <<: *application-base
    image: mysql:8.0
    container_name: ai_talks_database
    environment:
      MYSQL_ROOT_PASSWORD: v3ryD1ff1cultP@55w0Rd
      MYSQL_DATABASE: ai_talks
    volumes:
      - ./mysql-init:/docker-entrypoint-initdb.d/

  ai_talks_adminer:
    <<: *application-base
    image: adminer
    container_name: ai_talks_adminer
    depends_on:
      - ai_talks_database
    ports:
      - 18080:8080

  ai_talks:
    <<: *environmental-base
    container_name: ai_talks_api
    environment:
      API_PORT: 13000
      OLLAMA_HOST: ai_host:11434
      DB_HOST: ai_talks_database
      DB_PORT: 3306
      DB_USER: root
      DB_PASS: v3ryD1ff1cultP@55w0Rd
      DB_NAME: ai_talks
    build:
      context: .
      dockerfile: ./Dockerfile.app
      target: dev
    working_dir: /app
    depends_on:
      - ai_talks_database
      - ai_talks_adminer
      - ai_host
    volumes:
      - .:/app
    ports:
      - 13000:13000
    expose:
      - 13000
    command: [ sh, -c, 'npm run start:conversation:dev' ]

networks:
  ai_talks_network:
